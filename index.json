[{"authors":["admin"],"categories":null,"content":"Kristian Jensen is a Data Science student at the IT University of Copenhagen. His research interests include Natural Language Processing/Understanding, Artificial Intelligence and Robotics. He is currently pursuing a Master in Computer Science with a focus on Data Science and Machine Learning.\nHe works as a research assistant in the computer science lab run by Barbara Plank. Here he is currently aiding in research in the field of Natural Language Processing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"kris927b.github.io/author/kristian-n%C3%B8rgaard-jensen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"kris927b.github.io/author/kristian-n%C3%B8rgaard-jensen/","section":"authors","summary":"Kristian Jensen is a Data Science student at the IT University of Copenhagen. His research interests include Natural Language Processing/Understanding, Artificial Intelligence and Robotics. He is currently pursuing a Master in Computer Science with a focus on Data Science and Machine Learning.","tags":null,"title":"Kristian Nørgaard Jensen","type":"authors"},{"authors":["Kristian Nørgaard Jensen","Mike Zhang","Barbara Plank"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"68680b9edd0743c316ee346f031c5751","permalink":"kris927b.github.io/publication/jobstack/","publishdate":"2021-05-25T12:33:44+02:00","relpermalink":"kris927b.github.io/publication/jobstack/","section":"publication","summary":"De-identification is the task of detecting privacy-related entities in text, such as person names, emails and contact data. It has been well-studied within the medical domain. The need for deidentification technology is increasing, as privacy-preserving data handling is in high demand in many domains. In this paper, we focus on job postings. We present JOBSTACK, a new corpus for de-identification of personal data in job vacancies on Stackoverflow. We introduce baselines, comparing Long-Short Term Memory (LSTM) and Transformer models. To improve upon these baselines, we experiment with contextualized embeddings and distantly related auxiliary data via multi-task learning. Our results show that auxiliary data improves de-identification performance. Surprisingly, vanilla BERT turned out to be more effective than a BERT model trained on other portions of Stackoverflow.","tags":["De-Identification","Transformers","LSTM","MaChAmp"],"title":"De-identification of Privacy-related Entities in Job Postings","type":"publication"},{"authors":["Kristian Nørgaard Jensen","Nicolaj Filrup Rasmussen","Marco Placenti","Thai Wang","Barbara Plank"],"categories":[],"content":"","date":1607731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607731200,"objectID":"1f748733129d6807a372df78fdda2cba","permalink":"kris927b.github.io/publication/semeval-2020/","publishdate":"2020-05-15T00:00:00Z","relpermalink":"kris927b.github.io/publication/semeval-2020/","section":"publication","summary":"This paper describes a system that aims at assessing humour intensity in edited news headlinesas part of the 7th task of SemEval2020 on “Humor, Emphasis and Sentiment”. Various factorsneed to be accounted for in order to assess the funniness of an edited headline. We propose anarchitecture that uses hand-crafted features, knowledge bases and a language model to understandhumour, and combines them in a regression model. Our system outperforms two baselines. Ingeneral, automatic humour assessment remains a difficult task.","tags":[],"title":"Buhscitu at SEMEVAL-2020 Task 7: Assessing Humour in Edited NewsHeadlines using Hand-Crafted Features and Online Knowledge Bases","type":"publication"},{"authors":["Barbara Plank","Kristian Nørgaard Jensen","Rob van der Goot"],"categories":[],"content":"","date":1607558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607558400,"objectID":"8bfa2f90e031861f8209a1ebdf235da8","permalink":"kris927b.github.io/publication/dan_plus/","publishdate":"2020-11-27T16:33:14+01:00","relpermalink":"kris927b.github.io/publication/dan_plus/","section":"publication","summary":"This paper introduces DAN+, a multi-domain resource for nested named entities (NEs) and lexical normalization for Danish, a less-resourced language. We empirically assess three strategies to model the two-layer NE annotations, cross-lingual cross-domain transfer from German versus in-language annotation, language-specific versus multilingual BERT, and the effect of lexical normalization on Danish NE. Our results show that the most robust strategy is multi-task learning which is rivaled by multi-label decoding, transfer is successful also for zero-shot, and in-language BERT and lexical normalization works the best on the least canonical data. However, our results also show that out-of-domain remains challenging, while performance on news plateaus quickly. This highlights the importance of cross-domain evaluation of cross-lingual transfer.","tags":[],"title":"DAN+: Danish Nested Named Entities and Lexical Normalization","type":"publication"},{"authors":["Kristian Nørgaard Jensen"],"categories":["Python"],"content":"","date":1594729555,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594729555,"objectID":"f15dc5972611598396cee255c555af63","permalink":"kris927b.github.io/project/neat/","publishdate":"2020-07-14T14:25:55+02:00","relpermalink":"kris927b.github.io/project/neat/","section":"project","summary":"This repository contains a wrapper for the NEAT (Evolving Neural Networks through Augmenting Topologies) Algorithm. And a scenario of using it in the Gym environments from OpenAI","tags":["NEAT","Evolution","Neural Network","OpenAI Gym"],"title":"NEAT Wrapper","type":"project"},{"authors":["Kristian Nørgaard Jensen"],"categories":["Javascript","Typescript"],"content":"","date":1594727378,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594727378,"objectID":"997dcc53946c3a6a48440352d7af372e","permalink":"kris927b.github.io/project/stan/","publishdate":"2020-07-14T13:49:38+02:00","relpermalink":"kris927b.github.io/project/stan/","section":"project","summary":"Simple slackbot to chat with. Can respond on various commands such as '@stan tell me a joke' or '@stan send a gif with dogs'","tags":["Slack","Bot"],"title":"Stan SlackBot","type":"project"},{"authors":["Kristian Nørgaard Jensen","Nicolaj Filrup Rasmussen","Marco Placenti","Thai Wang"],"categories":["Python"],"content":"","date":1594726828,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594726828,"objectID":"1d3d0fbf8bc176a9a0aaa71141f97adc","permalink":"kris927b.github.io/project/humorheadlines/","publishdate":"2020-07-14T13:40:28+02:00","relpermalink":"kris927b.github.io/project/humorheadlines/","section":"project","summary":"Humour intensity regression using deep neural nets and hand-crafted features","tags":["NLP","Deep Learning","Humour Intensity"],"title":"Humour Headlines","type":"project"},{"authors":["Kristian Nørgaard Jensen","Nicolaj Filrup Rasmussen","Marco Placenti","Thai Wang"],"categories":[],"content":"","date":1589500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589500800,"objectID":"48ac6d8f8216002bf150d9101ba30280","permalink":"kris927b.github.io/publication/bsc-thesis/","publishdate":"2020-05-15T16:33:35+02:00","relpermalink":"kris927b.github.io/publication/bsc-thesis/","section":"publication","summary":"In this thesis we develop an architecture aimed at tackling humour intensity prediction. The task has a continuous label space contrary to much previous work, which has mostly concerned itself with discrete (and often binary) classification. Using a combination of techniques the regression model seeks to incorporate many aspects of humour. By combining modern neural encoders with classical hand-crafted features and neural language models we hypothesise that it is possible to capture many perspectives of the complex task. By comparing a variety of configurations to relevant baselines we conclude that the proposed model performs well. An ablation study shows that the main contributor to the models success is the neural language model. By analysing the components further the work seeks to explore why this is, and proposes some possible answers for why the components underperform, and how this can be addressed in future work.","tags":[],"title":"BSc Thesis: Assessing Humour in Edited News Headlines using Hand-Crafted Features and Online Knowledge Bases","type":"publication"},{"authors":["Nicolaj Filrup Rasmussen","Kristian Nørgaard Jensen","Marco Placenti","Thai Wang"],"categories":[],"content":"","date":1569542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569542400,"objectID":"e35c85630a78a5e786f3bae990fb3c59","permalink":"kris927b.github.io/publication/nodalida-paper/","publishdate":"2020-05-15T16:17:52+02:00","relpermalink":"kris927b.github.io/publication/nodalida-paper/","section":"publication","summary":"Due to the differences between reviews in different product categories, creating a general model for crossdomain sentiment classification can be a difficult task. This paper proposes an architecture that incorporates domain knowledge into a neural sentiment classification model. In addition to providing a cross-domain model, this also provides a quantifiable representation of the domains as numeric vectors. We show that it is possible to cluster the domain vectors and provide qualitative insights into the interdomain relations. We also a) present a new data set for sentiment classification that includes a domain parameter and preprocessed data points, and b) perform an ablation study in order to determine whether some word groups impact performance.","tags":[],"title":"Cross-Domain Sentiment Classification using Vector Embedded Domain Representation","type":"publication"}]